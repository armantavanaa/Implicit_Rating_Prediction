{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2bGdwp5wnm4_"
   },
   "source": [
    "We tried for around 20 times on Kaggle, and showed part of them here. The best trial would be our trial 19 as seen on Kaggle with a loss score as 0.41989."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "zisiPUVBKuQh"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.autograd as autograd \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "5f7GoYC8K1M2"
   },
   "outputs": [],
   "source": [
    "item = pd.read_csv('item_feature.csv')\n",
    "train = pd.read_csv('training.csv')\n",
    "df = train.merge(item, on = 'item_id', how = 'left')\n",
    "df['label'] =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "hg1eeAaMLNu1"
   },
   "outputs": [],
   "source": [
    "# Random Negative Sample\n",
    "u = np.random.randint(low=0.0, high=df.user_id.max(), size=int(len(df)*3))\n",
    "i = np.random.randint(low=0.0, high=df.item_id.max(), size=int(len(df)*3))\n",
    "c = np.random.randint(low=0.0, high=df.context_feature_id.max(), size=int(len(df)*3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "_LrBIlsILT_b"
   },
   "outputs": [],
   "source": [
    "sample= pd.concat([pd.Series(u),pd.Series(i),pd.Series(c)], axis =1).\\\n",
    "rename(columns={0:'user_id', 1:'item_id', 2:'context_feature_id'})\n",
    "sample = sample.merge(item, on = 'item_id', how = 'left')\n",
    "sample['label'] = 0\n",
    "df = pd.concat([df,sample])\n",
    "df = df.drop_duplicates(subset=['user_id','item_id']).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "DFE1a6nBk7eY",
    "outputId": "b205d5a3-2fb9-4255-937f-7bde2caa9fe2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>context_feature_id</th>\n",
       "      <th>item_feature_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>28366</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>16109</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>11500</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>20750</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>8759</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3772931</th>\n",
       "      <td>13279</td>\n",
       "      <td>39020</td>\n",
       "      <td>1</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3772932</th>\n",
       "      <td>161997</td>\n",
       "      <td>28197</td>\n",
       "      <td>2</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3772933</th>\n",
       "      <td>189188</td>\n",
       "      <td>25692</td>\n",
       "      <td>2</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3772934</th>\n",
       "      <td>37728</td>\n",
       "      <td>3128</td>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3772935</th>\n",
       "      <td>32972</td>\n",
       "      <td>3549</td>\n",
       "      <td>1</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3772936 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  item_id  context_feature_id  item_feature_id  label\n",
       "0              0    28366                   2                7      1\n",
       "1              0    16109                   2                7      1\n",
       "2              0    11500                   3                7      1\n",
       "3              0    20750                   2                7      1\n",
       "4              0     8759                   2                7      1\n",
       "...          ...      ...                 ...              ...    ...\n",
       "3772931    13279    39020                   1              138      0\n",
       "3772932   161997    28197                   2              142      0\n",
       "3772933   189188    25692                   2              138      0\n",
       "3772934    37728     3128                   1              148      0\n",
       "3772935    32972     3549                   1              142      0\n",
       "\n",
       "[3772936 rows x 5 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "G5aUDosLLXAM"
   },
   "outputs": [],
   "source": [
    "pos = df[df.label ==1].reset_index(drop = True)\n",
    "neg = df[df.label ==0].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "-Q4n_DLmNxin"
   },
   "outputs": [],
   "source": [
    "# Define sample function for multiple sampling every 2 or 3 epoch in training/val\n",
    "# for the purpose of cross validation\n",
    "def data_sample(pos, neg):\n",
    "\n",
    "    msk = np.random.rand(len(pos)) < 0.8\n",
    "    train_pos = pos[msk].reset_index(drop = True)\n",
    "    val_pos = pos[~msk].reset_index(drop = True)\n",
    "\n",
    "    msk = np.random.rand(len(neg)) < 0.8\n",
    "    train_neg = neg[msk].sample(frac = len(pos)/len(neg)).reset_index(drop = True)\n",
    "    val_neg = neg[~msk].sample(frac = len(pos)/len(neg)).reset_index(drop = True)\n",
    "\n",
    "    train = pd.concat([train_pos, train_neg]).sample(frac=1).reset_index(drop = True)\n",
    "    val = pd.concat([val_pos, val_neg]).sample(frac=1).reset_index(drop = True)\n",
    "\n",
    "    return train, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "tLmH4KX1MLzE"
   },
   "outputs": [],
   "source": [
    "train, val = data_sample(pos, neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQa1sEIck7eb"
   },
   "source": [
    "### Model 1: Basic Matrix Factorization Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "5E0mlmLbPZ5u"
   },
   "outputs": [],
   "source": [
    "class MF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, emb_size=100, seed=23):\n",
    "        super(MF, self).__init__()\n",
    "        torch.manual_seed(seed)\n",
    "        self.user_emb = nn.Embedding(num_users, emb_size)\n",
    "        self.user_bias = nn.Embedding(num_users, 1)\n",
    "        self.item_emb = nn.Embedding(num_items, emb_size)\n",
    "        self.item_bias = nn.Embedding(num_items, 1)\n",
    "        self.user_emb.weight.data.uniform_(0, 0.05)\n",
    "        self.item_emb.weight.data.uniform_(0, 0.05)\n",
    "        self.user_bias.weight.data.uniform_(-0.01, 0.01)\n",
    "        self.item_bias.weight.data.uniform_(-0.01, 0.01)\n",
    "\n",
    "    def forward(self, u, v):\n",
    "        U = self.user_emb(u)\n",
    "        V = self.item_emb(v)\n",
    "        b_u = self.user_bias(u).squeeze()\n",
    "        b_v = self.item_bias(v).squeeze()\n",
    "        return torch.sigmoid((U * V).sum(1) + b_u + b_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "HKAZM17zPi5o"
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_df, optimizer):\n",
    "    \"\"\" Trains the model for one epoch\"\"\"\n",
    "    model.train()\n",
    "    y = torch.FloatTensor(train_df.label.values)\n",
    "    u = torch.LongTensor(train_df.user_id.values)\n",
    "    v = torch.LongTensor(train_df.item_id.values)\n",
    "    y_hat = model(u,v)\n",
    "    output = torch.as_tensor(y_hat > 0.5, dtype = torch.int8)\n",
    "    train_acc = accuracy_score(output,y)\n",
    "    train_loss = F.binary_cross_entropy(y_hat, y)\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    return train_loss.item(), train_acc\n",
    "\n",
    "def valid_metrics(model, valid_df):\n",
    "    \"\"\"Computes validation loss and accuracy\"\"\"\n",
    "    model.eval()\n",
    "    u = torch.LongTensor(valid_df.user_id.values)\n",
    "    v = torch.LongTensor(valid_df.item_id.values)\n",
    "    y = torch.FloatTensor(valid_df.label.values)\n",
    "    y_hat = model(u,v)\n",
    "    valid_loss = F.binary_cross_entropy(y_hat, y)\n",
    "    output = torch.as_tensor(y_hat > 0.5, dtype = torch.int8)\n",
    "    auc = roc_auc_score( y.detach().numpy(), y_hat.detach().numpy())\n",
    "    valid_acc = accuracy_score(output,y)\n",
    "    return valid_loss.item(), valid_acc, auc\n",
    "\n",
    "def training(model, pos, neg, epochs=10, lr=0.01, wd=0.0):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    train, val = data_sample(pos, neg)\n",
    "    for i in range(epochs):\n",
    "        train_loss, train_acc = train_one_epoch(model, train, optimizer)\n",
    "        valid_loss, valid_acc, auc = valid_metrics(model, val) \n",
    "        if i%5==0: \n",
    "            print(\"train loss %.3f train acc %.3f valid loss %.3f valid acc %.3f roc auc acc %.3f\" % (train_loss,train_acc,valid_loss, valid_acc, auc)) \n",
    "        if i%3 == 0: \n",
    "            train, val = data_sample(pos, neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g17oolHePk_t",
    "outputId": "5ed7f2f7-49fa-4cd4-9b4e-1092c894e05b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.693 train acc 0.500 valid loss 0.687 valid acc 0.568 roc auc acc 0.496\n",
      "train loss 0.302 train acc 0.885 valid loss 0.318 valid acc 0.875 roc auc acc 0.941\n",
      "train loss 0.284 train acc 0.909 valid loss 0.291 valid acc 0.909 roc auc acc 0.967\n",
      "train loss 0.208 train acc 0.956 valid loss 0.257 valid acc 0.928 roc auc acc 0.975\n",
      "train loss 0.192 train acc 0.961 valid loss 0.216 valid acc 0.947 roc auc acc 0.986\n",
      "train loss 0.188 train acc 0.960 valid loss 0.193 valid acc 0.956 roc auc acc 0.991\n",
      "train loss 0.161 train acc 0.971 valid loss 0.207 valid acc 0.943 roc auc acc 0.987\n",
      "train loss 0.176 train acc 0.963 valid loss 0.198 valid acc 0.951 roc auc acc 0.990\n",
      "train loss 0.186 train acc 0.961 valid loss 0.192 valid acc 0.958 roc auc acc 0.992\n",
      "train loss 0.169 train acc 0.971 valid loss 0.211 valid acc 0.946 roc auc acc 0.988\n",
      "train loss 0.181 train acc 0.965 valid loss 0.201 valid acc 0.953 roc auc acc 0.991\n"
     ]
    }
   ],
   "source": [
    "model = MF(df.user_id.max()+1, df.item_id.max()+1, emb_size=50) \n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-5)\n",
    "training(model, pos, neg, epochs=51, lr=0.1, wd=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rO0J8FFEQ2Bu",
    "outputId": "fe33e953-1950-4e18-deea-cc03c4d19e61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.187 train acc 0.962 valid loss 0.189 valid acc 0.961 roc auc acc 0.993\n",
      "train loss 0.181 train acc 0.966 valid loss 0.185 valid acc 0.964 roc auc acc 0.995\n",
      "train loss 0.182 train acc 0.967 valid loss 0.183 valid acc 0.967 roc auc acc 0.996\n",
      "train loss 0.178 train acc 0.969 valid loss 0.185 valid acc 0.965 roc auc acc 0.995\n",
      "train loss 0.178 train acc 0.968 valid loss 0.181 valid acc 0.967 roc auc acc 0.996\n",
      "train loss 0.178 train acc 0.969 valid loss 0.178 valid acc 0.969 roc auc acc 0.996\n",
      "train loss 0.175 train acc 0.970 valid loss 0.181 valid acc 0.967 roc auc acc 0.996\n",
      "train loss 0.175 train acc 0.970 valid loss 0.178 valid acc 0.969 roc auc acc 0.996\n",
      "train loss 0.175 train acc 0.970 valid loss 0.176 valid acc 0.970 roc auc acc 0.997\n",
      "train loss 0.173 train acc 0.971 valid loss 0.178 valid acc 0.969 roc auc acc 0.996\n",
      "train loss 0.174 train acc 0.971 valid loss 0.177 valid acc 0.969 roc auc acc 0.997\n"
     ]
    }
   ],
   "source": [
    "training(model, pos, neg, epochs=51, lr=0.01, wd=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dv3dUHZhSjCm",
    "outputId": "bd1b6b95-11a8-40ae-ebc2-bd2273fcc215"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42271720177773114"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test_kaggle.csv')\n",
    "u = torch.LongTensor(test.user_id.values)\n",
    "v = torch.LongTensor(test.item_id.values)\n",
    "y_hat = model(u,v)\n",
    "prob = pd.Series(y_hat.detach().numpy()).reset_index().rename(columns = {'index':'id',0:'rating'})\n",
    "# see how many probability prediction are over 0.5\n",
    "sum(prob.rating>0.5)/len(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "EjOusz6QTBzC"
   },
   "outputs": [],
   "source": [
    "prob.to_csv('trial4.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6AmEFQVek7ei"
   },
   "source": [
    "### Model 2 (best so far)\n",
    "### Add ReLU and Dropout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "1hw-hhd6O1SB"
   },
   "outputs": [],
   "source": [
    "class MF2(nn.Module):\n",
    "    def __init__(self, num_users, num_items, emb_size=20):\n",
    "        super(MF2, self).__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, emb_size)\n",
    "        self.user_bias = nn.Embedding(num_users, 1)\n",
    "        self.item_emb = nn.Embedding(num_items, emb_size)\n",
    "        self.item_bias = nn.Embedding(num_items, 1)\n",
    "        # init \n",
    "        self.user_emb.weight.data.uniform_(0,0.05)\n",
    "        self.item_emb.weight.data.uniform_(0,0.05)\n",
    "        self.user_bias.weight.data.uniform_(-0.01,0.01)\n",
    "        self.item_bias.weight.data.uniform_(-0.01,0.01)\n",
    "        self.classifier = nn.Sigmoid()\n",
    "        self.nonlin = nn.ReLU()\n",
    "        self.drop = nn.Dropout(p = 0.1)\n",
    "        \n",
    "    def forward(self, u, v):\n",
    "        U = self.user_emb(u)\n",
    "        U = self.nonlin(U)\n",
    "        V = self.item_emb(v)\n",
    "        V = self.drop(V)\n",
    "        b_u = self.user_bias(u).squeeze()\n",
    "        b_v = self.item_bias(v).squeeze()\n",
    "        return self.classifier((U*V).sum(1) +  b_u  + b_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "Y0lrU84sPUcY",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "895129fb-aa0e-4e4f-eea5-73f13f73b91d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.693 train acc 0.500 valid loss 0.617 valid acc 0.832 roc auc acc 0.866\n",
      "train loss 0.291 train acc 0.884 valid loss 0.331 valid acc 0.877 roc auc acc 0.942\n",
      "train loss 0.292 train acc 0.907 valid loss 0.295 valid acc 0.907 roc auc acc 0.968\n",
      "train loss 0.248 train acc 0.929 valid loss 0.282 valid acc 0.910 roc auc acc 0.967\n",
      "train loss 0.235 train acc 0.928 valid loss 0.252 valid acc 0.917 roc auc acc 0.974\n",
      "train loss 0.234 train acc 0.927 valid loss 0.238 valid acc 0.925 roc auc acc 0.978\n",
      "train loss 0.213 train acc 0.941 valid loss 0.250 valid acc 0.920 roc auc acc 0.974\n",
      "train loss 0.217 train acc 0.941 valid loss 0.234 valid acc 0.932 roc auc acc 0.980\n",
      "train loss 0.218 train acc 0.942 valid loss 0.221 valid acc 0.941 roc auc acc 0.985\n",
      "train loss 0.199 train acc 0.952 valid loss 0.234 valid acc 0.932 roc auc acc 0.981\n",
      "train loss 0.206 train acc 0.950 valid loss 0.221 valid acc 0.941 roc auc acc 0.985\n",
      "train loss 0.210 train acc 0.948 valid loss 0.213 valid acc 0.946 roc auc acc 0.988\n",
      "train loss 0.195 train acc 0.956 valid loss 0.228 valid acc 0.937 roc auc acc 0.983\n",
      "train loss 0.202 train acc 0.952 valid loss 0.217 valid acc 0.944 roc auc acc 0.987\n",
      "train loss 0.207 train acc 0.949 valid loss 0.210 valid acc 0.948 roc auc acc 0.988\n",
      "train loss 0.194 train acc 0.956 valid loss 0.225 valid acc 0.939 roc auc acc 0.984\n",
      "train loss 0.201 train acc 0.953 valid loss 0.216 valid acc 0.944 roc auc acc 0.987\n",
      "train loss 0.206 train acc 0.950 valid loss 0.209 valid acc 0.949 roc auc acc 0.989\n",
      "train loss 0.193 train acc 0.957 valid loss 0.223 valid acc 0.940 roc auc acc 0.984\n",
      "train loss 0.200 train acc 0.953 valid loss 0.214 valid acc 0.945 roc auc acc 0.987\n",
      "train loss 0.205 train acc 0.951 valid loss 0.208 valid acc 0.949 roc auc acc 0.989\n"
     ]
    }
   ],
   "source": [
    "model2 = MF2(df.user_id.max()+1, df.item_id.max()+1, emb_size=75) \n",
    "training(model2, pos, neg, epochs=101, lr=0.1, wd=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "EMYTaxXTPcR6",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "93080b4b-37dd-45d5-b124-9c7e5853f7e8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.205 train acc 0.951 valid loss 0.205 valid acc 0.951 roc auc acc 0.990\n",
      "train loss 0.202 train acc 0.953 valid loss 0.204 valid acc 0.953 roc auc acc 0.991\n",
      "train loss 0.203 train acc 0.953 valid loss 0.202 valid acc 0.954 roc auc acc 0.992\n",
      "train loss 0.200 train acc 0.955 valid loss 0.203 valid acc 0.953 roc auc acc 0.991\n",
      "train loss 0.200 train acc 0.954 valid loss 0.201 valid acc 0.954 roc auc acc 0.992\n",
      "train loss 0.200 train acc 0.954 valid loss 0.199 valid acc 0.955 roc auc acc 0.992\n",
      "train loss 0.198 train acc 0.956 valid loss 0.200 valid acc 0.955 roc auc acc 0.992\n",
      "train loss 0.198 train acc 0.956 valid loss 0.198 valid acc 0.956 roc auc acc 0.992\n",
      "train loss 0.198 train acc 0.956 valid loss 0.197 valid acc 0.956 roc auc acc 0.993\n",
      "train loss 0.196 train acc 0.957 valid loss 0.198 valid acc 0.956 roc auc acc 0.992\n",
      "train loss 0.197 train acc 0.957 valid loss 0.196 valid acc 0.957 roc auc acc 0.993\n"
     ]
    }
   ],
   "source": [
    "training(model2, pos, neg, epochs=51, lr=0.01, wd=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LESGoHr2RMe7",
    "outputId": "3be795c8-ed77-450a-92d0-85674a68b45f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4084245578614786"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test_kaggle.csv')\n",
    "u = torch.LongTensor(test.user_id.values)\n",
    "v = torch.LongTensor(test.item_id.values)\n",
    "y_hat = model2(u,v)\n",
    "prob = pd.Series(y_hat.detach().numpy()).reset_index().rename(columns = {'index':'id',0:'rating'})\n",
    "sum(prob.rating>0.5)/len(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "BtFR1a08SCl0"
   },
   "outputs": [],
   "source": [
    "prob.to_csv('trial5.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E71W7R5xk7el"
   },
   "source": [
    "### Tuning parameters\n",
    "#### Change the resample frequency from every 3 epochs to 2.\n",
    "#### Play around with other parameters: epoch, embedding size, learning rate, weight decay...\n",
    "#### We show our trial 8, 11, 13, 14, 15 here. Trial 13 perfoms the best with a loss score as 0.42518."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "eoPKRloak7el",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_df, optimizer):\n",
    "    \"\"\" Trains the model for one epoch\"\"\"\n",
    "    model.train()\n",
    "    y = torch.FloatTensor(train_df.label.values)\n",
    "    u = torch.LongTensor(train_df.user_id.values)\n",
    "    v = torch.LongTensor(train_df.item_id.values)\n",
    "    y_hat = model(u,v)\n",
    "    output = torch.as_tensor(y_hat > 0.5, dtype = torch.int8)\n",
    "    train_acc = accuracy_score(output,y)\n",
    "    train_loss = F.binary_cross_entropy(y_hat, y)\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    return train_loss.item(), train_acc\n",
    "\n",
    "def valid_metrics(model, valid_df):\n",
    "    \"\"\"Computes validation loss and accuracy\"\"\"\n",
    "    model.eval()\n",
    "    u = torch.LongTensor(valid_df.user_id.values)\n",
    "    v = torch.LongTensor(valid_df.item_id.values)\n",
    "    y = torch.FloatTensor(valid_df.label.values)\n",
    "    y_hat = model(u,v)\n",
    "    valid_loss = F.binary_cross_entropy(y_hat, y)\n",
    "    output = torch.as_tensor(y_hat > 0.5, dtype = torch.int8)\n",
    "    auc = roc_auc_score( y.detach().numpy(), y_hat.detach().numpy())\n",
    "    valid_acc = accuracy_score(output,y)\n",
    "    return valid_loss.item(), valid_acc, auc\n",
    "\n",
    "def training(model, pos, neg, epochs=10, lr=0.01, wd=0.0):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    train, val = data_sample(pos, neg)\n",
    "    for i in range(epochs):\n",
    "        train_loss, train_acc = train_one_epoch(model, train, optimizer)\n",
    "        valid_loss, valid_acc, auc = valid_metrics(model, val) \n",
    "        if i%10== 0:\n",
    "            print(\"train loss %.3f train acc %.3f valid loss %.3f valid acc %.3f roc auc acc %.3f\" % (train_loss,train_acc,valid_loss, valid_acc, auc)) \n",
    "        if i%2 == 0: \n",
    "            train, val = data_sample(pos, neg)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "olvV2iavk7em",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "0759c389-2782-45d0-e5ec-ad3eb837ebc9",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.693 train acc 0.500 valid loss 0.618 valid acc 0.831 roc auc acc 0.865\n",
      "train loss 0.285 train acc 0.909 valid loss 0.306 valid acc 0.902 roc auc acc 0.964\n",
      "train loss 0.233 train acc 0.929 valid loss 0.250 valid acc 0.919 roc auc acc 0.975\n",
      "train loss 0.218 train acc 0.939 valid loss 0.234 valid acc 0.931 roc auc acc 0.980\n",
      "train loss 0.207 train acc 0.948 valid loss 0.223 valid acc 0.939 roc auc acc 0.984\n",
      "train loss 0.202 train acc 0.952 valid loss 0.218 valid acc 0.943 roc auc acc 0.987\n",
      "train loss 0.200 train acc 0.954 valid loss 0.215 valid acc 0.945 roc auc acc 0.988\n",
      "train loss 0.199 train acc 0.954 valid loss 0.213 valid acc 0.947 roc auc acc 0.988\n",
      "train loss 0.198 train acc 0.955 valid loss 0.212 valid acc 0.947 roc auc acc 0.988\n",
      "train loss 0.198 train acc 0.955 valid loss 0.211 valid acc 0.947 roc auc acc 0.988\n",
      "train loss 0.198 train acc 0.955 valid loss 0.211 valid acc 0.947 roc auc acc 0.988\n",
      "train loss 0.197 train acc 0.955 valid loss 0.211 valid acc 0.947 roc auc acc 0.988\n",
      "train loss 0.197 train acc 0.955 valid loss 0.211 valid acc 0.947 roc auc acc 0.988\n"
     ]
    }
   ],
   "source": [
    "model_8 = MF2(df.user_id.max()+1, df.item_id.max()+1, emb_size=75) \n",
    "training(model_8, pos, neg, epochs=126, lr=0.1, wd=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "RASd4c2Ck7em",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "65247e93-8928-4a19-98e3-f598022b0596",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.202 train acc 0.953 valid loss 0.200 valid acc 0.955 roc auc acc 0.991\n",
      "train loss 0.201 train acc 0.953 valid loss 0.199 valid acc 0.955 roc auc acc 0.992\n",
      "train loss 0.201 train acc 0.954 valid loss 0.199 valid acc 0.955 roc auc acc 0.992\n",
      "train loss 0.200 train acc 0.954 valid loss 0.199 valid acc 0.956 roc auc acc 0.992\n",
      "train loss 0.200 train acc 0.955 valid loss 0.198 valid acc 0.956 roc auc acc 0.992\n",
      "train loss 0.200 train acc 0.955 valid loss 0.198 valid acc 0.956 roc auc acc 0.992\n",
      "train loss 0.199 train acc 0.955 valid loss 0.198 valid acc 0.956 roc auc acc 0.992\n",
      "train loss 0.199 train acc 0.955 valid loss 0.198 valid acc 0.956 roc auc acc 0.993\n",
      "train loss 0.199 train acc 0.955 valid loss 0.197 valid acc 0.956 roc auc acc 0.993\n",
      "train loss 0.199 train acc 0.956 valid loss 0.197 valid acc 0.957 roc auc acc 0.993\n",
      "train loss 0.198 train acc 0.956 valid loss 0.197 valid acc 0.957 roc auc acc 0.993\n",
      "train loss 0.198 train acc 0.956 valid loss 0.197 valid acc 0.957 roc auc acc 0.993\n",
      "train loss 0.198 train acc 0.956 valid loss 0.197 valid acc 0.956 roc auc acc 0.993\n"
     ]
    }
   ],
   "source": [
    "training(model_8, pos, neg, epochs=126, lr=0.001, wd=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C8O9L29kk7em",
    "outputId": "5a9677ba-cd54-48d1-ea81-bbbc0199b4fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4057002766233596"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test_kaggle.csv')\n",
    "u = torch.LongTensor(test.user_id.values)\n",
    "v = torch.LongTensor(test.item_id.values)\n",
    "y_hat = model_8(u,v)\n",
    "prob = pd.Series(y_hat.detach().numpy()).reset_index().rename(columns = {'index':'id',0:'rating'})\n",
    "sum(prob.rating > 0.5) / len(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "mG_LJQhsk7en"
   },
   "outputs": [],
   "source": [
    "prob.to_csv('trial8.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "CZv-GchZk7eo",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "3772e953-5d18-49a8-c2e8-7dbe1f55bba6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.693 train acc 0.500 valid loss 0.599 valid acc 0.842 roc auc acc 0.865\n",
      "train loss 0.224 train acc 0.933 valid loss 0.244 valid acc 0.926 roc auc acc 0.976\n",
      "train loss 0.144 train acc 0.969 valid loss 0.159 valid acc 0.962 roc auc acc 0.991\n",
      "train loss 0.128 train acc 0.979 valid loss 0.145 valid acc 0.971 roc auc acc 0.995\n",
      "train loss 0.118 train acc 0.982 valid loss 0.132 valid acc 0.975 roc auc acc 0.996\n",
      "train loss 0.113 train acc 0.985 valid loss 0.126 valid acc 0.978 roc auc acc 0.997\n",
      "train loss 0.110 train acc 0.986 valid loss 0.123 valid acc 0.980 roc auc acc 0.998\n",
      "train loss 0.109 train acc 0.986 valid loss 0.122 valid acc 0.981 roc auc acc 0.998\n",
      "train loss 0.108 train acc 0.986 valid loss 0.121 valid acc 0.981 roc auc acc 0.998\n",
      "train loss 0.108 train acc 0.987 valid loss 0.120 valid acc 0.981 roc auc acc 0.998\n",
      "train loss 0.107 train acc 0.987 valid loss 0.119 valid acc 0.982 roc auc acc 0.998\n",
      "train loss 0.107 train acc 0.987 valid loss 0.119 valid acc 0.981 roc auc acc 0.998\n",
      "train loss 0.107 train acc 0.987 valid loss 0.119 valid acc 0.981 roc auc acc 0.998\n"
     ]
    }
   ],
   "source": [
    "model_9 = MF2(df.user_id.max()+1, df.item_id.max()+1,emb_size=75) \n",
    "training(model_9, pos, neg, epochs=126, lr=0.1, wd=5e-07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "gLhrnfPLk7eo",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "e4265e3d-73b8-4356-a595-e5873bfbd64e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.111 train acc 0.985 valid loss 0.109 valid acc 0.987 roc auc acc 0.999\n",
      "train loss 0.111 train acc 0.985 valid loss 0.108 valid acc 0.987 roc auc acc 0.999\n",
      "train loss 0.111 train acc 0.985 valid loss 0.108 valid acc 0.987 roc auc acc 0.999\n",
      "train loss 0.111 train acc 0.985 valid loss 0.109 valid acc 0.987 roc auc acc 0.999\n",
      "train loss 0.111 train acc 0.985 valid loss 0.108 valid acc 0.987 roc auc acc 0.999\n",
      "train loss 0.111 train acc 0.985 valid loss 0.109 valid acc 0.987 roc auc acc 0.999\n",
      "train loss 0.111 train acc 0.985 valid loss 0.109 valid acc 0.987 roc auc acc 0.999\n",
      "train loss 0.111 train acc 0.985 valid loss 0.109 valid acc 0.987 roc auc acc 0.999\n",
      "train loss 0.111 train acc 0.985 valid loss 0.109 valid acc 0.987 roc auc acc 0.999\n",
      "train loss 0.111 train acc 0.985 valid loss 0.109 valid acc 0.987 roc auc acc 0.999\n",
      "train loss 0.111 train acc 0.985 valid loss 0.108 valid acc 0.987 roc auc acc 0.999\n",
      "train loss 0.111 train acc 0.985 valid loss 0.109 valid acc 0.987 roc auc acc 0.999\n",
      "train loss 0.111 train acc 0.985 valid loss 0.109 valid acc 0.987 roc auc acc 0.999\n"
     ]
    }
   ],
   "source": [
    "training(model_9, pos, neg, epochs=126, lr=0.00001, wd=5e-07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2x272a6zk7eo",
    "outputId": "35f3c675-bd0f-4b54-bc6c-ccb62f199686"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3593167009714593"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test_kaggle.csv')\n",
    "u = torch.LongTensor(test.user_id.values)\n",
    "v = torch.LongTensor(test.item_id.values)\n",
    "y_hat = model_9(u,v)\n",
    "prob = pd.Series(y_hat.detach().numpy()).reset_index().rename(columns = {'index':'id',0:'rating'})\n",
    "sum(prob.rating>0.5)/len(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "yJaomGn5k7ep"
   },
   "outputs": [],
   "source": [
    "prob.to_csv('trial11.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "8dhby2cuk7eq",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "ea1ca942-b367-4e13-cf1c-7b952abdfda2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.694 train acc 0.500 valid loss 0.618 valid acc 0.831 roc auc acc 0.864\n",
      "train loss 0.284 train acc 0.911 valid loss 0.306 valid acc 0.902 roc auc acc 0.965\n",
      "train loss 0.231 train acc 0.932 valid loss 0.249 valid acc 0.921 roc auc acc 0.976\n",
      "train loss 0.214 train acc 0.941 valid loss 0.232 valid acc 0.932 roc auc acc 0.981\n",
      "train loss 0.205 train acc 0.949 valid loss 0.221 valid acc 0.940 roc auc acc 0.985\n",
      "train loss 0.200 train acc 0.953 valid loss 0.216 valid acc 0.944 roc auc acc 0.987\n",
      "train loss 0.198 train acc 0.955 valid loss 0.213 valid acc 0.946 roc auc acc 0.988\n",
      "train loss 0.197 train acc 0.955 valid loss 0.213 valid acc 0.947 roc auc acc 0.988\n",
      "train loss 0.197 train acc 0.956 valid loss 0.211 valid acc 0.948 roc auc acc 0.989\n",
      "train loss 0.196 train acc 0.956 valid loss 0.211 valid acc 0.948 roc auc acc 0.989\n",
      "train loss 0.196 train acc 0.956 valid loss 0.210 valid acc 0.949 roc auc acc 0.989\n",
      "train loss 0.196 train acc 0.956 valid loss 0.209 valid acc 0.949 roc auc acc 0.989\n",
      "train loss 0.196 train acc 0.956 valid loss 0.209 valid acc 0.949 roc auc acc 0.989\n"
     ]
    }
   ],
   "source": [
    "model_13 = MF2(df.user_id.max()+1, df.item_id.max()+1, emb_size=100) \n",
    "training(model_13, pos, neg, epochs=126, lr=.09, wd=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t3D0yAUVk7eq",
    "outputId": "2aa2942a-2382-4f10-8603-f9064ff4f70a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4047432384598241"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test_kaggle.csv')\n",
    "u = torch.LongTensor(test.user_id.values)\n",
    "v = torch.LongTensor(test.item_id.values)\n",
    "y_hat = model_13(u,v)\n",
    "prob = pd.Series(y_hat.detach().numpy()).reset_index().rename(columns = {'index':'id',0:'rating'})\n",
    "sum(prob.rating>0.5)/len(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "HT8rccYKk7er"
   },
   "outputs": [],
   "source": [
    "prob.to_csv('trial13.csv',index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "3hqYwwVvk7er",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "0e94b27d-7fb0-48cc-a28d-c03adca7d0cb",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.693 train acc 0.500 valid loss 0.624 valid acc 0.830 roc auc acc 0.868\n",
      "train loss 0.286 train acc 0.906 valid loss 0.306 valid acc 0.900 roc auc acc 0.964\n",
      "train loss 0.238 train acc 0.926 valid loss 0.252 valid acc 0.918 roc auc acc 0.974\n",
      "train loss 0.221 train acc 0.936 valid loss 0.237 valid acc 0.928 roc auc acc 0.979\n",
      "train loss 0.210 train acc 0.946 valid loss 0.225 valid acc 0.938 roc auc acc 0.984\n",
      "train loss 0.203 train acc 0.951 valid loss 0.218 valid acc 0.942 roc auc acc 0.986\n",
      "train loss 0.202 train acc 0.953 valid loss 0.215 valid acc 0.944 roc auc acc 0.987\n",
      "train loss 0.200 train acc 0.953 valid loss 0.214 valid acc 0.945 roc auc acc 0.988\n",
      "train loss 0.200 train acc 0.953 valid loss 0.212 valid acc 0.947 roc auc acc 0.988\n",
      "train loss 0.199 train acc 0.954 valid loss 0.212 valid acc 0.947 roc auc acc 0.988\n",
      "train loss 0.199 train acc 0.954 valid loss 0.212 valid acc 0.947 roc auc acc 0.988\n",
      "train loss 0.199 train acc 0.954 valid loss 0.211 valid acc 0.947 roc auc acc 0.988\n",
      "train loss 0.198 train acc 0.954 valid loss 0.211 valid acc 0.947 roc auc acc 0.988\n",
      "train loss 0.199 train acc 0.955 valid loss 0.211 valid acc 0.947 roc auc acc 0.988\n",
      "train loss 0.198 train acc 0.955 valid loss 0.211 valid acc 0.947 roc auc acc 0.988\n",
      "train loss 0.198 train acc 0.954 valid loss 0.210 valid acc 0.948 roc auc acc 0.988\n",
      "train loss 0.199 train acc 0.954 valid loss 0.211 valid acc 0.948 roc auc acc 0.988\n",
      "train loss 0.199 train acc 0.955 valid loss 0.211 valid acc 0.948 roc auc acc 0.988\n",
      "train loss 0.198 train acc 0.954 valid loss 0.211 valid acc 0.948 roc auc acc 0.988\n",
      "train loss 0.198 train acc 0.955 valid loss 0.211 valid acc 0.948 roc auc acc 0.988\n",
      "train loss 0.199 train acc 0.955 valid loss 0.210 valid acc 0.948 roc auc acc 0.988\n",
      "train loss 0.199 train acc 0.954 valid loss 0.211 valid acc 0.948 roc auc acc 0.988\n",
      "train loss 0.199 train acc 0.955 valid loss 0.211 valid acc 0.948 roc auc acc 0.988\n",
      "train loss 0.198 train acc 0.954 valid loss 0.211 valid acc 0.948 roc auc acc 0.988\n",
      "train loss 0.199 train acc 0.955 valid loss 0.211 valid acc 0.948 roc auc acc 0.988\n",
      "train loss 0.198 train acc 0.955 valid loss 0.211 valid acc 0.947 roc auc acc 0.988\n"
     ]
    }
   ],
   "source": [
    "model_14 = MF2(df.user_id.max()+1, df.item_id.max()+1, emb_size=60) \n",
    "training(model_14, pos, neg, epochs=251, lr=.1, wd=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Aw6GveuKk7er",
    "outputId": "9a823997-730a-4e13-b22b-74d83f6a8bfc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40841406977201516"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test_kaggle.csv')\n",
    "u = torch.LongTensor(test.user_id.values)\n",
    "v = torch.LongTensor(test.item_id.values)\n",
    "y_hat = model_14(u,v)\n",
    "prob = pd.Series(y_hat.detach().numpy()).reset_index().rename(columns = {'index':'id',0:'rating'})\n",
    "sum(prob.rating>0.5)/len(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "fUSfLSfek7es"
   },
   "outputs": [],
   "source": [
    "prob.to_csv('trial14.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "q-DoOx5wk7es",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "908e776e-fedc-4782-bdb5-85a550bc00b4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.694 train acc 0.500 valid loss 0.611 valid acc 0.834 roc auc acc 0.863\n",
      "train loss 0.284 train acc 0.913 valid loss 0.306 valid acc 0.905 roc auc acc 0.965\n",
      "train loss 0.228 train acc 0.934 valid loss 0.248 valid acc 0.922 roc auc acc 0.976\n",
      "train loss 0.212 train acc 0.943 valid loss 0.230 valid acc 0.933 roc auc acc 0.981\n",
      "train loss 0.202 train acc 0.951 valid loss 0.220 valid acc 0.940 roc auc acc 0.985\n",
      "train loss 0.198 train acc 0.954 valid loss 0.215 valid acc 0.945 roc auc acc 0.987\n",
      "train loss 0.197 train acc 0.955 valid loss 0.213 valid acc 0.946 roc auc acc 0.988\n",
      "train loss 0.195 train acc 0.956 valid loss 0.212 valid acc 0.947 roc auc acc 0.989\n",
      "train loss 0.195 train acc 0.957 valid loss 0.211 valid acc 0.948 roc auc acc 0.989\n",
      "train loss 0.195 train acc 0.957 valid loss 0.211 valid acc 0.948 roc auc acc 0.989\n",
      "train loss 0.195 train acc 0.957 valid loss 0.210 valid acc 0.949 roc auc acc 0.989\n",
      "train loss 0.195 train acc 0.957 valid loss 0.209 valid acc 0.949 roc auc acc 0.989\n",
      "train loss 0.195 train acc 0.957 valid loss 0.210 valid acc 0.948 roc auc acc 0.989\n",
      "train loss 0.195 train acc 0.957 valid loss 0.210 valid acc 0.949 roc auc acc 0.989\n",
      "train loss 0.195 train acc 0.957 valid loss 0.210 valid acc 0.948 roc auc acc 0.989\n",
      "train loss 0.195 train acc 0.957 valid loss 0.210 valid acc 0.949 roc auc acc 0.989\n",
      "train loss 0.195 train acc 0.957 valid loss 0.210 valid acc 0.948 roc auc acc 0.989\n",
      "train loss 0.195 train acc 0.957 valid loss 0.210 valid acc 0.949 roc auc acc 0.989\n",
      "train loss 0.195 train acc 0.957 valid loss 0.209 valid acc 0.949 roc auc acc 0.989\n",
      "train loss 0.195 train acc 0.957 valid loss 0.210 valid acc 0.949 roc auc acc 0.989\n",
      "train loss 0.195 train acc 0.957 valid loss 0.210 valid acc 0.949 roc auc acc 0.989\n",
      "train loss 0.195 train acc 0.957 valid loss 0.209 valid acc 0.949 roc auc acc 0.989\n",
      "train loss 0.195 train acc 0.957 valid loss 0.210 valid acc 0.949 roc auc acc 0.989\n",
      "train loss 0.195 train acc 0.957 valid loss 0.210 valid acc 0.949 roc auc acc 0.989\n",
      "train loss 0.195 train acc 0.957 valid loss 0.210 valid acc 0.949 roc auc acc 0.989\n",
      "train loss 0.195 train acc 0.957 valid loss 0.210 valid acc 0.949 roc auc acc 0.989\n"
     ]
    }
   ],
   "source": [
    "model_15 = MF2(df.user_id.max()+1, df.item_id.max()+1, emb_size=125) \n",
    "training(model_15, pos, neg, epochs=251, lr=.09, wd=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LqcP-MR_k7es",
    "outputId": "76ba7fb3-3224-4d3d-bc3e-8e26b54f818a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40132412129475464"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test_kaggle.csv')\n",
    "u = torch.LongTensor(test.user_id.values)\n",
    "v = torch.LongTensor(test.item_id.values)\n",
    "y_hat = model_15(u,v)\n",
    "prob = pd.Series(y_hat.detach().numpy()).reset_index().rename(columns = {'index':'id',0:'rating'})\n",
    "sum(prob.rating>0.5)/len(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "UacovWA9k7et"
   },
   "outputs": [],
   "source": [
    "prob.to_csv('trial15.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JtR9bwQLk7et"
   },
   "source": [
    "## Model3: Add more ReLU and Dropout layer\n",
    "### Trial 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "i6DaOI-hk7et"
   },
   "outputs": [],
   "source": [
    "class MF3(nn.Module):\n",
    "    def __init__(self, num_users, num_items, emb_size=20):\n",
    "        super(MF3, self).__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, emb_size)\n",
    "        self.user_bias = nn.Embedding(num_users, 1)\n",
    "        self.item_emb = nn.Embedding(num_items, emb_size)\n",
    "        self.item_bias = nn.Embedding(num_items, 1)\n",
    "        # init \n",
    "        self.user_emb.weight.data.uniform_(0,0.05)\n",
    "        self.item_emb.weight.data.uniform_(0,0.05)\n",
    "        self.user_bias.weight.data.uniform_(-0.01,0.01)\n",
    "        self.item_bias.weight.data.uniform_(-0.01,0.01)\n",
    "        self.classifier = nn.Sigmoid()\n",
    "        self.nonlin = nn.ReLU()\n",
    "        self.nonlin2 = nn.ReLU()\n",
    "        self.drop = nn.Dropout(p = 0.05)\n",
    "        self.drop2 = nn.Dropout(p = 0.05)\n",
    "        \n",
    "    def forward(self, u, v):\n",
    "        U = self.user_emb(u)\n",
    "        U = self.nonlin(U)\n",
    "        U = self.drop(U)\n",
    "        V = self.item_emb(v)\n",
    "        V = self.nonlin2(V)\n",
    "        V = self.drop2(V)\n",
    "        b_u = self.user_bias(u).squeeze()\n",
    "        b_v = self.item_bias(v).squeeze()\n",
    "        return self.classifier((U*V).sum(1) +  b_u  + b_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "G0sw1ahdk7eu",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "703e637f-1e64-4a32-8321-e8f4626f4e02",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.693 train acc 0.500 valid loss 0.629 valid acc 0.773 roc auc acc 0.852\n",
      "train loss 0.325 train acc 0.891 valid loss 0.336 valid acc 0.886 roc auc acc 0.953\n",
      "train loss 0.261 train acc 0.906 valid loss 0.277 valid acc 0.900 roc auc acc 0.965\n",
      "train loss 0.253 train acc 0.916 valid loss 0.266 valid acc 0.911 roc auc acc 0.970\n",
      "train loss 0.241 train acc 0.928 valid loss 0.253 valid acc 0.922 roc auc acc 0.976\n",
      "train loss 0.227 train acc 0.938 valid loss 0.238 valid acc 0.933 roc auc acc 0.981\n",
      "train loss 0.221 train acc 0.943 valid loss 0.233 valid acc 0.937 roc auc acc 0.983\n",
      "train loss 0.220 train acc 0.945 valid loss 0.231 valid acc 0.939 roc auc acc 0.984\n"
     ]
    }
   ],
   "source": [
    "model_16 = MF3(df.user_id.max()+1, df.item_id.max()+1, emb_size=75) \n",
    "training(model_16, pos, neg, epochs=76, lr=.1, wd=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "rLEsGGr4k7eu",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "54b26601-b9af-4264-c069-1d2bbb483ee5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.223 train acc 0.943 valid loss 0.221 valid acc 0.945 roc auc acc 0.987\n",
      "train loss 0.222 train acc 0.944 valid loss 0.220 valid acc 0.945 roc auc acc 0.987\n",
      "train loss 0.221 train acc 0.944 valid loss 0.219 valid acc 0.946 roc auc acc 0.987\n",
      "train loss 0.220 train acc 0.945 valid loss 0.219 valid acc 0.946 roc auc acc 0.987\n",
      "train loss 0.220 train acc 0.945 valid loss 0.218 valid acc 0.947 roc auc acc 0.988\n",
      "train loss 0.220 train acc 0.945 valid loss 0.218 valid acc 0.947 roc auc acc 0.988\n",
      "train loss 0.219 train acc 0.945 valid loss 0.218 valid acc 0.947 roc auc acc 0.988\n",
      "train loss 0.219 train acc 0.946 valid loss 0.217 valid acc 0.947 roc auc acc 0.988\n"
     ]
    }
   ],
   "source": [
    "training(model_16, pos, neg, epochs=76, lr=.001, wd=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5bkl45yrk7eu",
    "outputId": "58e21c7a-2740-4d7e-945c-afea1267294e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3365, 0.2597, 0.7683,  ..., 0.8741, 0.8741, 0.1681],\n",
       "       grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test_kaggle.csv')\n",
    "u = torch.LongTensor(test.user_id.values)\n",
    "v = torch.LongTensor(test.item_id.values)\n",
    "y_hat = model_16(u,v)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QNliogHBk7eu",
    "outputId": "c5bd0b79-d2b6-42b1-fdb4-7767ef0dda65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.391179516761278"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = pd.Series(y_hat.detach().numpy()).reset_index().rename(columns = {'index':'id',0:'rating'})\n",
    "sum(prob.rating>0.5)/len(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "Buot1320k7ev"
   },
   "outputs": [],
   "source": [
    "prob.to_csv('trial16.csv',index = False) # 12 and 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v6mmPk_wk7ev"
   },
   "source": [
    "## Revisit Model 2\n",
    "### Trial 17 and 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VUBpWCGKk7ev",
    "outputId": "30608184-f031-4fdf-a247-fbf0b081107e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.694 train acc 0.500 valid loss 0.639 valid acc 0.829 roc auc acc 0.867\n",
      "train loss 0.285 train acc 0.901 valid loss 0.309 valid acc 0.894 roc auc acc 0.960\n",
      "train loss 0.247 train acc 0.929 valid loss 0.256 valid acc 0.923 roc auc acc 0.977\n",
      "train loss 0.221 train acc 0.938 valid loss 0.235 valid acc 0.931 roc auc acc 0.981\n",
      "train loss 0.212 train acc 0.946 valid loss 0.224 valid acc 0.939 roc auc acc 0.985\n",
      "train loss 0.203 train acc 0.951 valid loss 0.215 valid acc 0.944 roc auc acc 0.987\n",
      "train loss 0.200 train acc 0.953 valid loss 0.211 valid acc 0.947 roc auc acc 0.989\n",
      "train loss 0.198 train acc 0.955 valid loss 0.210 valid acc 0.948 roc auc acc 0.989\n",
      "train loss 0.197 train acc 0.956 valid loss 0.208 valid acc 0.949 roc auc acc 0.990\n",
      "train loss 0.196 train acc 0.956 valid loss 0.207 valid acc 0.950 roc auc acc 0.990\n",
      "train loss 0.196 train acc 0.956 valid loss 0.208 valid acc 0.949 roc auc acc 0.990\n"
     ]
    }
   ],
   "source": [
    "model_17 = MF2(df.user_id.max()+1, df.item_id.max()+1, emb_size=90) \n",
    "training(model_17, pos, neg, epochs=101, lr=.07, wd=1e-6) # trail 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jUNgK81_k7ev",
    "outputId": "307fb9d7-807c-4ea1-d319-5c490b481fb7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3272, 0.2307, 0.6433,  ..., 0.7915, 0.7915, 0.1271],\n",
       "       grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test_kaggle.csv')\n",
    "u = torch.LongTensor(test.user_id.values)\n",
    "v = torch.LongTensor(test.item_id.values)\n",
    "y_hat = model_17(u,v)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ZnsgG46k7ew",
    "outputId": "77d2b2d0-d1f9-4ccb-d6fb-f7aafad9dc99"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41192495771988935"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = pd.Series(y_hat.detach().numpy()).reset_index().rename(columns = {'index':'id',0:'rating'})\n",
    "sum(prob.rating>0.5)/len(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "P9NlWeZyk7ew"
   },
   "outputs": [],
   "source": [
    "prob.to_csv('trial17.csv',index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L4KxFKLDk7ew",
    "outputId": "331e008c-821d-45b4-d7d1-6189235b5bc1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.199 train acc 0.954 valid loss 0.198 valid acc 0.955 roc auc acc 0.992\n",
      "train loss 0.200 train acc 0.954 valid loss 0.198 valid acc 0.955 roc auc acc 0.992\n",
      "train loss 0.199 train acc 0.954 valid loss 0.198 valid acc 0.956 roc auc acc 0.992\n",
      "train loss 0.199 train acc 0.954 valid loss 0.198 valid acc 0.956 roc auc acc 0.992\n",
      "train loss 0.199 train acc 0.955 valid loss 0.199 valid acc 0.956 roc auc acc 0.992\n",
      "train loss 0.199 train acc 0.955 valid loss 0.198 valid acc 0.955 roc auc acc 0.992\n"
     ]
    }
   ],
   "source": [
    "training(model_17, pos, neg, epochs=51, lr=.0001, wd=1e-6) # trial 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DboZwrU0k7ex",
    "outputId": "a0269a3b-93a4-4191-f245-ccce775901f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.411948555921182"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test_kaggle.csv')\n",
    "u = torch.LongTensor(test.user_id.values)\n",
    "v = torch.LongTensor(test.item_id.values)\n",
    "y_hat = model_17(u,v)\n",
    "prob = pd.Series(y_hat.detach().numpy()).reset_index().rename(columns = {'index':'id',0:'rating'})\n",
    "sum(prob.rating>0.5)/len(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "aPnVYm8Hk7ey"
   },
   "outputs": [],
   "source": [
    "prob.to_csv('trial18.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning the hyperparam in random negative sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "executionInfo": {
     "elapsed": 555,
     "status": "ok",
     "timestamp": 1644645329784,
     "user": {
      "displayName": "Zhao Kaihang",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "12474067113521262852"
     },
     "user_tz": 480
    },
    "id": "5f7GoYC8K1M2"
   },
   "outputs": [],
   "source": [
    "item = pd.read_csv('item_feature.csv')\n",
    "train = pd.read_csv('training.csv')\n",
    "df = train.merge(item, on = 'item_id', how = 'left')\n",
    "df['label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "executionInfo": {
     "elapsed": 633,
     "status": "ok",
     "timestamp": 1644645333677,
     "user": {
      "displayName": "Zhao Kaihang",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "12474067113521262852"
     },
     "user_tz": 480
    },
    "id": "hg1eeAaMLNu1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Random Negative Sample\n",
    "u = np.random.randint(low=0.0, high=df.user_id.max(), size=int(len(df)*2))\n",
    "i = np.random.randint(low=0.0, high=df.item_id.max(), size=int(len(df)*2))\n",
    "c = np.random.randint(low=0.0, high=df.context_feature_id.max(), size=int(len(df)*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "executionInfo": {
     "elapsed": 5291,
     "status": "ok",
     "timestamp": 1644645339795,
     "user": {
      "displayName": "Zhao Kaihang",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "12474067113521262852"
     },
     "user_tz": 480
    },
    "id": "_LrBIlsILT_b"
   },
   "outputs": [],
   "source": [
    "sample= pd.concat([pd.Series(u),pd.Series(i),pd.Series(c)], axis =1).\\\n",
    "rename(columns={0:'user_id', 1:'item_id', 2:'context_feature_id'})\n",
    "sample = sample.merge(item, on = 'item_id', how = 'left')\n",
    "sample['label'] = 0\n",
    "df = pd.concat([df,sample])\n",
    "df = df.drop_duplicates(subset=['user_id','item_id']).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "G5aUDosLLXAM"
   },
   "outputs": [],
   "source": [
    "pos = df[df.label ==1].reset_index(drop = True)\n",
    "neg = df[df.label ==0].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.693 train acc 0.500 valid loss 0.601 valid acc 0.837 roc auc acc 0.865\n",
      "train loss 0.271 train acc 0.918 valid loss 0.292 valid acc 0.908 roc auc acc 0.967\n",
      "train loss 0.219 train acc 0.935 valid loss 0.242 valid acc 0.922 roc auc acc 0.976\n",
      "train loss 0.208 train acc 0.947 valid loss 0.227 valid acc 0.937 roc auc acc 0.982\n",
      "train loss 0.198 train acc 0.954 valid loss 0.218 valid acc 0.942 roc auc acc 0.986\n",
      "train loss 0.195 train acc 0.957 valid loss 0.215 valid acc 0.945 roc auc acc 0.987\n",
      "train loss 0.194 train acc 0.957 valid loss 0.213 valid acc 0.946 roc auc acc 0.988\n",
      "train loss 0.193 train acc 0.958 valid loss 0.211 valid acc 0.948 roc auc acc 0.988\n",
      "train loss 0.192 train acc 0.958 valid loss 0.211 valid acc 0.948 roc auc acc 0.988\n",
      "train loss 0.192 train acc 0.958 valid loss 0.209 valid acc 0.948 roc auc acc 0.989\n",
      "train loss 0.192 train acc 0.959 valid loss 0.210 valid acc 0.948 roc auc acc 0.988\n",
      "train loss 0.192 train acc 0.958 valid loss 0.209 valid acc 0.949 roc auc acc 0.989\n",
      "train loss 0.192 train acc 0.959 valid loss 0.210 valid acc 0.948 roc auc acc 0.989\n"
     ]
    }
   ],
   "source": [
    "model_18 = MF2(df.user_id.max()+1, df.item_id.max()+1, emb_size=75) # our best result with test data\n",
    "training(model_18, pos, neg, epochs=126, lr=.12, wd=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 304,
     "status": "ok",
     "timestamp": 1644641673342,
     "user": {
      "displayName": "Zhao Kaihang",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "12474067113521262852"
     },
     "user_tz": 480
    },
    "id": "LESGoHr2RMe7",
    "outputId": "ea320880-220b-44d3-d194-c565babeaecc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4645, 0.2722, 0.8072,  ..., 0.9325, 0.9325, 0.1507],\n",
       "       grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test_kaggle.csv')\n",
    "u = torch.LongTensor(test.user_id.values)\n",
    "v = torch.LongTensor(test.item_id.values)\n",
    "y_hat = model_18(u,v)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 145,
     "status": "ok",
     "timestamp": 1644641677417,
     "user": {
      "displayName": "Zhao Kaihang",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "12474067113521262852"
     },
     "user_tz": 480
    },
    "id": "37Jt5uhtR_sx",
    "outputId": "c137b8ec-958b-4f0f-ac54-77be9a30af93"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4235090525322181"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = pd.Series(y_hat.detach().numpy()).reset_index().rename(columns = {'index':'id',0:'rating'})\n",
    "sum(prob.rating>0.5)/len(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "executionInfo": {
     "elapsed": 2566,
     "status": "ok",
     "timestamp": 1644641714431,
     "user": {
      "displayName": "Zhao Kaihang",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "12474067113521262852"
     },
     "user_tz": 480
    },
    "id": "BtFR1a08SCl0"
   },
   "outputs": [],
   "source": [
    "prob.to_csv('trial19.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "name": "Project_progress1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
